{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc84e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import sqlite3\n",
    "import time\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5e98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oauth = SpotifyOAuth(client_id=\"\", client_secret=\"\", scope =\"user-modify-playback-state\", redirect_uri=\"http://localhost:8080\")\n",
    "# sp = spotipy.Spotify(auth_manager=oauth)\n",
    "\n",
    "oauth = SpotifyOAuth(client_id=\"\", client_secret=\"\", scope =\"user-modify-playback-state\", redirect_uri=\"http://localhost:8080\")\n",
    "sp = spotipy.Spotify(auth_manager=oauth)\n",
    "data_path = \"..\\spotify_million_playlist_dataset\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aed4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO NOT TOUCH THIS CELL OR YOU MIGHT CLEAR THE WHOLE DATABASE\n",
    "# con = sqlite3.connect(\"playlistDB2.db\")\n",
    "# cur = con.cursor()\n",
    "# cur.execute(\"DROP TABLE IF EXISTS song\")\n",
    "# cur.execute(\"DROP TABLE IF EXISTS playlist\")\n",
    "# cur.execute(\"DROP TABLE IF EXISTS playlistsongs\")\n",
    "# cur.execute(\"CREATE TABLE song(danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, type, id, uri, track_href, analysis_url, duration_ms, time_signature)\")\n",
    "# cur.execute(\"CREATE TABLE playlist(pid, name, num_tracks)\")\n",
    "# cur.execute(\"CREATE TABLE playlistsongs(pid, uri, pos)\")\n",
    "# con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a9ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_cache = set()\n",
    "def process_songs(to_process, playlist):\n",
    "    result = []\n",
    "    song_features = sp.audio_features(to_process)\n",
    "    for sf in song_features:\n",
    "        if sf == None:\n",
    "            continue\n",
    "        song_cache.add(sf[\"uri\"])\n",
    "        result.append(tuple(sf.values()))\n",
    "    return result\n",
    "\n",
    "def process_artists(to_process):\n",
    "    result = []\n",
    "    song_features = sp.artists(to_process)\n",
    "    for sf in song_features:\n",
    "        if sf == None:\n",
    "            continue\n",
    "        song_cache.add(sf[\"uri\"])\n",
    "        result.append(tuple(sf.values()))\n",
    "    return result\n",
    "        \n",
    "\n",
    "def process_chunk(chunk):\n",
    "    to_process = []\n",
    "    playlists = []\n",
    "    songs = []\n",
    "    playlist_songs = []\n",
    "    artists = []\n",
    "    to_process_artists = []\n",
    "    for playlist in chunk[\"playlists\"]:\n",
    "        playlists.append((playlist[\"pid\"], playlist[\"name\"], playlist[\"num_tracks\"]))\n",
    "        for song in playlist[\"tracks\"]:\n",
    "            id = song[\"track_uri\"]\n",
    "            playlist_songs.append((playlist[\"pid\"], id, song[\"pos\"]))\n",
    "            if id in song_cache:\n",
    "                continue\n",
    "            to_process.append(id)\n",
    "            if len(to_process) == 100:\n",
    "                processed_songs = process_songs(to_process, playlist)\n",
    "                songs.extend(processed_songs)\n",
    "                to_process = []\n",
    "    \n",
    "    songs.extend(process_songs(to_process, playlist))\n",
    "    to_process = []\n",
    "    cur.executemany(f\"INSERT INTO song VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", songs)\n",
    "    cur.executemany(f\"INSERT INTO playlist VALUES(?, ?, ?)\", playlists)\n",
    "    cur.executemany(f\"INSERT INTO playlistsongs VALUES(?, ?, ?)\", playlist_songs)\n",
    "    con.commit()\n",
    "\n",
    "\n",
    "def process_chunk_get_artist(chunk):\n",
    "    to_process = []\n",
    "    artists_list = []\n",
    "    artists_seen = set()\n",
    "    for playlist in chunk[\"playlists\"]:\n",
    "        for song in playlist[\"tracks\"]:\n",
    "            artist = song[\"artist_uri\"]\n",
    "            id = song[\"track_uri\"]\n",
    "            if id in song_artist_map:\n",
    "                continue\n",
    "            song_artist_map[id] = artist\n",
    "            if artist in artist_map or artist in artists_seen:\n",
    "                continue\n",
    "            to_process.append(artist)\n",
    "            artists_seen.add(artist)\n",
    "            if len(to_process) == 50:\n",
    "                processed_artists = sp.artists(to_process)\n",
    "                artists_list.extend(processed_artists[\"artists\"])\n",
    "                to_process = []\n",
    "    if len(to_process) != 0:\n",
    "        artists_list.extend(sp.artists(to_process)[\"artists\"])\n",
    "    for artist in artists_list:\n",
    "        artist_map[artist[\"uri\"]] = artist\n",
    "\n",
    "def process_chunk_by_file_path(file):\n",
    "    print(f\"starting chunk {file}\")\n",
    "    chunk = json.load(open(f\"{data_path}/{file}\", \"r\"))\n",
    "    process_chunk_get_artist(chunk)\n",
    "    print(f\"finished chunk {file}\")\n",
    "    del chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed970c",
   "metadata": {},
   "source": [
    "# Notes for processing Artists\n",
    "\n",
    "295860 artists in the dataset\n",
    "295860 artists / 50 artist per api call = 5918 api calls\n",
    "\n",
    "if we make an api call every 15 seconds: 25 hours to process artists\n",
    "if we make an api call every 20 seconds: 32 hours to process artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1587220b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in data from ..\\spotify_million_playlist_dataset\\data, starting at 2AM\n",
      "starting on slice 0-999\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "time_start = time.time()\n",
    "print(f\"Loading in data from {data_path}, starting at 2AM\")\n",
    "song_artist_map = pickle.load(open(\"data/song_artists.dat\", \"rb\"))\n",
    "artist_map = pickle.load(open(\"data/artists_info.dat\", \"rb\"))\n",
    "for file in os.listdir(data_path):\n",
    "    chunk = json.load(open(f\"{data_path}/{file}\", \"r\"))\n",
    "    print(f\"starting on slice {chunk['info']['slice']}\")\n",
    "    process_chunk_get_artist(chunk)\n",
    "    del chunk\n",
    "    pickle.dump(artist_map, open(\"data/artists_info.dat\", \"wb\"))\n",
    "    pickle.dump(song_artist_map, open(\"data/song_artists.dat\", \"wb\"))\n",
    "    \n",
    "    print(f\"Completed {i} chunks\")\n",
    "    i += 1\n",
    "time_done = time.time()\n",
    "print(f\"done creating database in {(time_done - time_start)/60} minutes\")\n",
    "os.system(f'send_message \"done creating database in {(time_done - time_start)/60} minutes\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb410c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ThreadPool(mp.cpu_count()) as p:\n",
    "#     p.map(process_chunk_by_file_path, os.listdir(data_path))\n",
    "\n",
    "# import pickle\n",
    "# to_dump = {song: artist_map[artist] for song, artist in song_artist_map.items()}\n",
    "# pickle.dump(to_dump, open(\"data/artists.dat\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "05dc0d43ac7da59c082e08edbbeccab9d61272ec2075ab8bea0ba48ce46022d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
